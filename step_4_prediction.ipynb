{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import open_clip\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "import psutil\n",
    "from lavis.models.eva_vit import create_eva_vit_g\n",
    "from lavis.common.registry import registry\n",
    "from omegaconf import OmegaConf\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import cv2\n",
    "cpu_device = torch.device('cpu')\n",
    "gpu_device = torch.device('cuda')\n",
    "\n",
    "# use eval for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mem_stats():\n",
    "    mem = psutil.virtual_memory()\n",
    "    total_system_memory = mem.total / (1024 ** 2)\n",
    "    used_system_memory = mem.used / (1024 ** 2)\n",
    "    total_gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024 ** 2)\n",
    "    reserved_gpu_memory = torch.cuda.memory_reserved(0) / (1024 ** 2)\n",
    "    allocated_gpu_memory = torch.cuda.memory_allocated(0) / (1024 ** 2)\n",
    "    percent_gpu_total = (allocated_gpu_memory / total_gpu_memory)*100\n",
    "    percent_gpu_reserved = (reserved_gpu_memory / total_gpu_memory)*100\n",
    "    percent_cpu_total = (used_system_memory / total_system_memory)*100\n",
    "    print(f\"mem used gpu: {allocated_gpu_memory:.2f} MB, reserved gpu: {reserved_gpu_memory:.2f}MB -> {percent_gpu_total:.2f}% of total, {percent_gpu_reserved:.2f}% reserved\")\n",
    "    print(f\"mem used cpu: {used_system_memory:.2f} MB -> {percent_cpu_total:.2f}% of total\")\n",
    "\n",
    "print_mem_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixelwise_features = torch.load(\"blip_noneva_pixelwise_rendfet_features_reduced.pt\").unsqueeze(0).float()\n",
    "xyz_pts = torch.load(\"blip_noneva_pixelwise_rendfet_xyz_reduced.pt\").unsqueeze(0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"checkpoints/pretrain_blip2_sam_flant5xl_v2.pth\"\n",
    "model_cfg = {\n",
    "    \"arch\": \"blip2_t5\",\n",
    "    \"model_type\": \"pretrain_flant5xl\",\n",
    "    \"use_grad_checkpoint\": False,\n",
    "}\n",
    "model_cfg = OmegaConf.create(model_cfg)\n",
    "print_mem_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = registry.get_model_class(\"blip2_t5\").from_pretrained(model_type=\"pretrain_flant5xl\")\n",
    "print_mem_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "print_mem_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint[\"model\"], strict=False)\n",
    "print_mem_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(cpu_device)\n",
    "print_mem_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_cfg = {\"name\": \"blip_question\", \"prompt\": \"\"}\n",
    "processor_cfg = OmegaConf.create(processor_cfg)\n",
    "text_processor = registry.get_processor_class(processor_cfg.name).from_config(processor_cfg)\n",
    "print_mem_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfeat = pixelwise_features.to(cpu_device)\n",
    "xyz_pts = xyz_pts.to(cpu_device)\n",
    "prompt = text_processor(\"Describe the 3D scene in one sentence.\")\n",
    "\n",
    "model_inputs = {\"text_input\": prompt, \"pc_feat\": outfeat, \"pc\": xyz_pts}\n",
    "model_outputs = model.predict_answers(\n",
    "    samples=model_inputs,\n",
    "    max_len=50,\n",
    "    length_penalty=1.2,\n",
    "    repetition_penalty=1.5,\n",
    ")\n",
    "model_outputs = model_outputs[0]\n",
    "print(model_outputs)\n",
    "print_mem_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "ax = plt.figure().add_subplot(111, projection=\"3d\")\n",
    "tsne = TSNE(n_components=3, random_state=0, learning_rate=200, init=\"random\")\n",
    "idx = np.random.choice(outfeat.shape[1], 10000)\n",
    "pc_feature = outfeat[:, idx, :]\n",
    "pc_points = xyz_pts[:, idx, :]\n",
    "pc_feature = pc_feature.squeeze(0).cpu().numpy()  # (N, 1408)\n",
    "pc_points = pc_points.squeeze(0).cpu().numpy()  # (N, 3)\n",
    "pc_feature = tsne.fit_transform(pc_feature)  # (N, 3)\n",
    "pc_feature = (pc_feature - pc_feature.min()) / (pc_feature.max() - pc_feature.min() + 1e-6) # normalize\n",
    "ax.scatter(pc_points[:, 0], pc_points[:, 1], pc_points[:, 2], c=pc_feature, s=1)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_zticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "alternative_feats = torch.load(\"/home/owenburns88/3D-LLM/3DLLM_BLIP2-base/assets/scene0480_00.pt\")\n",
    "alternative_pcs = torch.from_numpy(np.load(\"/home/owenburns88/3D-LLM/3DLLM_BLIP2-base/assets/scene0480_00.npy\"))\n",
    "pixelwise_features = torch.load(\"blip_noneva_pixelwise_rendfet_features_reduced.pt\")\n",
    "xyz_pts = torch.load(\"blip_noneva_pixelwise_rendfet_xyz_reduced.pt\")\n",
    "\n",
    "print(alternative_feats.shape)\n",
    "print(alternative_pcs.shape)\n",
    "print(pixelwise_features.shape)\n",
    "print(xyz_pts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "their_std = torch.std(alternative_feats, dim=0)\n",
    "their_mean = torch.mean(alternative_feats, dim=0)\n",
    "our_std = torch.std(pixelwise_features, dim=0)\n",
    "our_mean = torch.mean(pixelwise_features, dim=0)\n",
    "\n",
    "# plot a histogram\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axs = plt.subplots(2)\n",
    "axs[0].hist(their_std.numpy(), bins=100, alpha=0.5, label=\"their std\")\n",
    "axs[0].hist(our_std.numpy(), bins=100, alpha=0.5, label=\"our std\")\n",
    "axs[0].legend()\n",
    "axs[1].hist(their_mean.numpy(), bins=100, alpha=0.5, label=\"their mean\")\n",
    "axs[1].hist(our_mean.numpy(), bins=100, alpha=0.5, label=\"our mean\")\n",
    "axs[1].legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
