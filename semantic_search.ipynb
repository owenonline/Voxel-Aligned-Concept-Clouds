{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'h5py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# import torch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# torch.set_grad_enabled(False)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# import open_clip\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'h5py'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import h5py\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "torch.set_grad_enabled(False)\n",
    "import open_clip\n",
    "import pickle\n",
    "cpu_device = torch.device('cpu')\n",
    "gpu_device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the CLIP model\n",
    "\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(\"ViT-H-14\", \"laion2b_s32b_b79k\")\n",
    "model.cpu()\n",
    "model.eval()\n",
    "tokenizer = open_clip.get_tokenizer(\"ViT-H-14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ground truth bounding boxes\n",
    "import pickle\n",
    "\n",
    "with open('outputs.pkl', 'rb') as f:\n",
    "    outputs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = ['apple', 'milk', 'cereal', 'bread', 'banana', 'bin', 'ur5e', 'panda']\n",
    "bboxes = {}\n",
    "\n",
    "for object in objects:\n",
    "    object_points = outputs['xyz_pts'][outputs['segmentation_pts'][object]]\n",
    "    min_x = object_points[:, 0].min()\n",
    "    max_x = object_points[:, 0].max()\n",
    "    min_y = object_points[:, 1].min()\n",
    "    max_y = object_points[:, 1].max()\n",
    "    min_z = object_points[:, 2].min()\n",
    "    max_z = object_points[:, 2].max()\n",
    "    bboxes[object] = [(min_x, min_y, min_z), (max_x, max_y, max_z)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0596368, 0.2750703, 0.15055764), (0.8981135, 0.707657, 0.2649597)]\n"
     ]
    }
   ],
   "source": [
    "# print(bboxes['apple'])\n",
    "# bboxes['apple'] = [(-0.7769833, 0.3524605, 0.15017936), (-0.68268924, 0.4545155, 0.2483119)]\n",
    "\n",
    "# print(bboxes['banana'])\n",
    "# bboxes['banana'] = [(-0.37267345, 0.36484203, 0.15037148), (-0.13995615, 0.4852845, 0.19382282)]\n",
    "\n",
    "# print(bboxes['milk'])\n",
    "# bboxes['milk'] = [(-0.0752123, 0.5250703, 0.15051995), (0.0596368, 0.62811373, 0.34507185)]\n",
    "\n",
    "# print(bboxes['cereal'])\n",
    "# bboxes['cereal'] = [(-0.1052123, 0.3250703, 0.15051995), (0.0396368, 0.40811373, 0.34507185)]\n",
    "\n",
    "# print(bboxes['bin'])\n",
    "# bboxes['bin'] = [(0.0596368, 0.2750703, 0.15055764), (0.8581135, 0.707657, 0.2649597)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "# downsample the point cloud by randomly selecting points\n",
    "downsampled_indices = np.random.choice(outputs['xyz_pts'].shape[0], 100000, replace=False)\n",
    "downsampled_points = outputs['xyz_pts'][downsampled_indices]\n",
    "downsampled_colors = outputs['rgb_pts'][downsampled_indices] / 255\n",
    "\n",
    "def create_bounding_box_points_and_lines(bbox, color):\n",
    "    min_point = bbox[0]\n",
    "    max_point = bbox[1]\n",
    "\n",
    "    corners = np.array([\n",
    "        [min_point[0], min_point[1], min_point[2]],\n",
    "        [min_point[0], max_point[1], min_point[2]],\n",
    "        [max_point[0], max_point[1], min_point[2]],\n",
    "        [max_point[0], min_point[1], min_point[2]],\n",
    "        [min_point[0], min_point[1], max_point[2]],\n",
    "        [min_point[0], max_point[1], max_point[2]],\n",
    "        [max_point[0], max_point[1], max_point[2]],\n",
    "        [max_point[0], min_point[1], max_point[2]],\n",
    "    ])\n",
    "\n",
    "    # Create points and colors for the bounding box\n",
    "    bbox_points = o3d.utility.Vector3dVector(corners)\n",
    "    bbox_colors = o3d.utility.Vector3dVector([color for _ in range(corners.shape[0])])\n",
    "\n",
    "    return bbox_points, bbox_colors\n",
    "\n",
    "gt_bbox_points, gt_bbox_colors = create_bounding_box_points_and_lines(bboxes['bin'], [1, 1, 0])\n",
    "\n",
    "combined_points = np.vstack((np.asarray(downsampled_points), np.asarray(gt_bbox_points)))\n",
    "combined_colors = np.vstack((np.asarray(downsampled_colors), np.asarray(gt_bbox_colors)))\n",
    "\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "point_cloud.points = o3d.utility.Vector3dVector(combined_points)\n",
    "point_cloud.colors = o3d.utility.Vector3dVector(combined_colors)\n",
    "\n",
    "# Save the point cloud to a .ply file\n",
    "o3d.io.write_point_cloud(\"bbox_test.ply\", point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the point cloud and features\n",
    "\n",
    "with h5py.File(\"/home/owenburns88/concept-fusion/examples/saved-map/pointclouds/pc_points.h5\", \"r\") as f:\n",
    "    xyz_pts = torch.from_numpy(f[\"pc_points\"][:])\n",
    "\n",
    "with h5py.File(\"/home/owenburns88/concept-fusion/examples/saved-map/pointclouds/pc_embeddings.h5\", \"r\") as f:\n",
    "    pixelwise_features = torch.from_numpy(f[\"pc_embeddings\"][:])\n",
    "\n",
    "# with h5py.File(\"/home/owenburns88/concept-fusion/examples/saved-map/pointclouds/pc_colors.h5\", \"r\") as f:\n",
    "#     rgb_pts = torch.from_numpy(f[\"pc_colors\"][:]).float().numpy() / 255.0\n",
    "\n",
    "map_embeddings_norm = torch.nn.functional.normalize(pixelwise_features, dim=1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the search text\n",
    "\n",
    "text = tokenizer([\"red object\"])\n",
    "textfeat = model.encode_text(text.cpu())\n",
    "textfeat = torch.nn.functional.normalize(textfeat, dim=-1)\n",
    "textfeat = textfeat.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct the similarity search\n",
    "\n",
    "cosine_similarity = torch.nn.CosineSimilarity(dim=-1).to('cpu')\n",
    "\n",
    "# calculate the similarity between all of the pixel-level embeddings and the prompt, and scale it to the [0,1] range (normally [-1,1]) to serve as a colormap weight\n",
    "similarity = cosine_similarity(\n",
    "    map_embeddings_norm, textfeat\n",
    ")\n",
    "\n",
    "similarity_shifted = (similarity + 1.0) / 2.0 # shift the similarity to the [0,1] range\n",
    "\n",
    "similarity_rel = (similarity_shifted - similarity_shifted.min()) / (\n",
    "                similarity_shifted.max() - similarity_shifted.min() + 1e-12\n",
    "            ) # normalize the similarity to the [0,1] range\n",
    "\n",
    "similarity_rel_thresholded = similarity_rel.clone()\n",
    "similarity_rel_thresholded[similarity_rel_thresholded < 0.6] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the IoU score\n",
    "\n",
    "bounding_box = bboxes['apple']\n",
    "\n",
    "model_chosen_points = xyz_pts[similarity_rel_thresholded[0,:] >= 0.6]\n",
    "min_x = model_chosen_points[:, 0].min()\n",
    "max_x = model_chosen_points[:, 0].max()\n",
    "min_y = model_chosen_points[:, 1].min()\n",
    "max_y = model_chosen_points[:, 1].max()\n",
    "min_z = model_chosen_points[:, 2].min()\n",
    "max_z = model_chosen_points[:, 2].max()\n",
    "model_bounding_box = [(min_x, min_y, min_z), (max_x, max_y, max_z)]\n",
    "\n",
    "def iou(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0][0], boxB[0][0])\n",
    "    yA = max(boxA[0][1], boxB[0][1])\n",
    "    xB = min(boxA[1][0], boxB[1][0])\n",
    "    yB = min(boxA[1][1], boxB[1][1])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    # compute the area of both the prediction and ground-truth rectangles\n",
    "    boxAArea = (boxA[1][0] - boxA[0][0]) * (boxA[1][1] - boxA[0][1])\n",
    "    boxBArea = (boxB[1][0] - boxB[0][0]) * (boxB[1][1] - boxB[0][1])\n",
    "    # compute the intersection over union by taking the intersection area and dividing it by the sum of prediction + ground-truth areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n",
    "iou_score = iou(bounding_box, model_bounding_box)\n",
    "print(iou_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaccviz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
